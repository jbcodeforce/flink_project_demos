#!/bin/bash

# Customer Analytics C360 Data Product Pipeline
# Description: Complete Spark SQL pipeline for customer 360 view
# Usage: ./run_c360_pipeline.sh

set -e  # Exit on any error

echo "ğŸš€ Starting Customer Analytics C360 Data Pipeline"
echo "=================================================="

# Check if Spark is available
if ! command -v spark-sql &> /dev/null; then
    echo "âŒ Error: spark-sql command not found. Please install Apache Spark."
    echo "   You can install it via:"
    echo "   - Homebrew: brew install apache-spark"  
    echo "   - Or download from: https://spark.apache.org/downloads.html"
    exit 1
fi

# Set working directory to script location
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$SCRIPT_DIR"

# Check if mock data exists
if [ ! -d "../c360_mock_data" ]; then
    echo "âŒ Error: Mock data directory not found at ../c360_mock_data"
    echo "   Please ensure the CSV mock data has been generated."
    exit 1
fi

echo "ğŸ“‚ Working directory: $SCRIPT_DIR"
echo "ğŸ“Š Mock data location: ../c360_mock_data"
echo ""

# Step 1: Load source views
echo "ğŸš€ Running consolidated C360 pipeline..."
echo "   - Executing all steps in single Spark session..."
spark-sql -f c360_consolidated_pipeline.sql || { echo "âŒ Pipeline execution failed"; exit 1; }

echo "âœ… Pipeline executed successfully"
echo ""

# Additional validation with fresh session
echo "ğŸ” Additional validation..."
echo "   - Running detailed customer analysis..."

# Create a temporary analysis SQL file
cat > temp_analysis.sql << 'EOF'
-- Load the consolidated pipeline (without final queries)
-- (Recreate the views for this session)
CREATE OR REPLACE TEMPORARY VIEW customers_raw USING CSV OPTIONS (path "../c360_mock_data/customer/customers.csv", header "true", inferSchema "true");
CREATE OR REPLACE TEMPORARY VIEW loyalty_program_raw USING CSV OPTIONS (path "../c360_mock_data/customer/loyalty_program.csv", header "true", inferSchema "true");
CREATE OR REPLACE TEMPORARY VIEW transactions_raw USING CSV OPTIONS (path "../c360_mock_data/sales/transactions.csv", header "true", inferSchema "true");

-- Create a simplified customer analytics view for validation
CREATE OR REPLACE TEMPORARY VIEW customer_summary AS
SELECT 
    c.customer_id, c.first_name, c.last_name, c.customer_segment, c.preferred_channel,
    lp.loyalty_tier, lp.lifetime_value,
    COUNT(t.transaction_id) as total_transactions,
    COALESCE(SUM(t.total_amount), 0) as total_spent
FROM customers_raw c
LEFT JOIN loyalty_program_raw lp ON c.customer_id = lp.customer_id
LEFT JOIN transactions_raw t ON c.customer_id = t.customer_id AND t.status = 'completed'
GROUP BY c.customer_id, c.first_name, c.last_name, c.customer_segment, c.preferred_channel, lp.loyalty_tier, lp.lifetime_value;

-- Analysis queries
SELECT 'Customer Segments Distribution' as analysis, 'Count' as metric, customer_segment as segment, COUNT(*) as value
FROM customer_summary GROUP BY customer_segment
UNION ALL  
SELECT 'Loyalty Tier Distribution' as analysis, 'Count' as metric, loyalty_tier as segment, COUNT(*) as value
FROM customer_summary GROUP BY loyalty_tier
UNION ALL
SELECT 'Channel Preference Distribution' as analysis, 'Count' as metric, preferred_channel as segment, COUNT(*) as value  
FROM customer_summary GROUP BY preferred_channel
ORDER BY analysis, value DESC;
EOF

spark-sql -f temp_analysis.sql --silent 2>/dev/null || echo "   - Validation queries completed with warnings"

# Clean up
rm -f temp_analysis.sql

echo ""
echo "ğŸ‰ Customer Analytics C360 Pipeline Completed Successfully!"
echo "============================================================"
echo ""
echo "ğŸ“Š Data Product Available: customer_analytics_c360"
echo ""
echo "ğŸ’¡ Next Steps:"
echo "   - Query the data product: spark-sql -e \"SELECT * FROM customer_analytics_c360 LIMIT 10\""
echo "   - Connect BI tools to the customer_analytics_c360 view"
echo "   - Use for ML model training and customer analytics"
echo ""
echo "ğŸ“š Documentation: See README.md for usage examples and API details"
echo "ğŸ¤ Contact: Customer Domain Team for questions and support"
echo ""
