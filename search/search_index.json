{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Flink Project Demonstrations","text":"<p>This git repository includes multiple projects to illustrate shifting from batch processing to data stream processing using Flink, and how to manage data as a product.</p> <ol> <li>The first project is a classical customer 360 assessment. The different components are in the customer_360 folder. It starts from one Spark project to illustrate how to implement a customer 360 analytic data product using Apache Spark batch processing, then supports the same semantic with a data streaming processing using Apache Flink. This examples illustrates how to use Agentic solution to automate most of the migration using the shit_left utilities</li> <li>The project <code>online_store</code> illustrates starting from a white page to process online store activities for customer behavior and real-time inventory. This is a fictuous demonstration to build using a set of incremental labs.</li> </ol>"},{"location":"#customer-360-introduction","title":"Customer 360 introduction","text":"<p>The high level architecture for  batch processing is presented in the figure below, and use a simplified version of the star schema of the Kimball methodology, to build dimensional models:</p> <p></p> <p>To shift left by moving the batch-based Spark processing to a real-time processing with Kafka and Flink project, the architecture looks like:</p> <p></p> <p>The project also demonstrates an automatic migration from Spark to Flink using the shift_left tool and agentic AI.</p>"},{"location":"#a-data-as-a-product-design","title":"A data as a product design","text":"<p>Any data as a product design starts by assessing the domain, the data ownership, the data sources, and consumer of the analytic data products,... We recommend to read this chapter to review a methodology to build data as a product.</p> <p>The specific customer 360 use case is a multi-channel retailer (bricks-and-mortar stores, e-commerce, mobile app) migrating their analytics platform to an Analytics Lakehouse with real-time processing.</p> <p>The project identifies the following key business domains and assigning the following ownership:</p> Domain Data Owner/Team Key Data Sources Customer Customer Experience/CRM Team CRM system, loyalty program, support tickets, app usage logs Sales Finance/Sales Operations Team Point of Sale (POS) system, e-commerce transactions, regional sales ledgers Product Merchandising Team Product catalog, inventory system, supplier data Logistics Supply Chain Team Warehouse management, shipping manifests, tracking data <p>The Customer Domain Team is responsible for building a core data product named, the Customer 360 Data Product.</p> Metadata Description Product Name: customer.analytics.C360 Purpose: To provide a comprehensive, high-quality, and up-to-date view of a customer for analytics, BI, and ML initiatives across all other domains. Data Storage: Uses the Lakehouse's object storage in an open format (e.g. Iceberg tables) for ACID-compliant, performant data. Ingestion: Real-time are managed by the Customer Domain Team to ingest and transform raw data from source systems into the Lakehouse."},{"location":"#data-product-output","title":"Data Product Output:","text":"<p>The final curated data is exposed via well-defined, easily consumable interfaces: </p> <ul> <li>SQL Endpoint: A materialized view or table on the Lakehouse that other domains can query directly using SQL.</li> <li>API Service: A REST API for low-latency, record-by-record lookups (e.g., for a personalized recommendation service).</li> <li>File Export: Secure, versioned file exports for large-scale ML model training.</li> </ul>"},{"location":"#data-product-characteristics","title":"Data Product Characteristics:","text":"<ul> <li>Discoverable: Registered in a central Data Catalog (a self-service component of the Mesh).</li> <li>Addressable: Has a unique identifier and clear documentation (customer.analytics.C360).</li> <li>Trustworthy: Includes built-in data quality checks (DQ) and validation rules enforced by the Customer Team.</li> <li>Self-Describing: Contains rich, up-to-date metadata (schema, lineage, ownership, DQ metrics).</li> <li>Secure &amp; Governed: Access is controlled using federated governance rules (e.g., fine-grained, tag-based access control on the Lakehouse).</li> </ul>"},{"location":"#cross-domain-consumption-for-analytics","title":"Cross-Domain Consumption for Analytics","text":"<p>Other domains may consume the data as a product to achieve their analytical goals:</p> Consuming Domain Analytical Goal Data Product Consumed Marketing Predict churn for a targeted email campaign. customer.analytics.Customer360Profile (to get demographics, loyalty score, purchase history). Product Analyze which customer segments are buying a new line of shoes. customer.analytics.Customer360Profile joined with the Sales Domain's sales.transaction.AggregatedDailySales product. Finance Calculate the Customer Lifetime Value (CLV) Queries the customer.analytics.Customer360Profile via the SQL endpoint. <p>To read more about moving from Domain Driven Design to Data as a product methodology see this chapter.</p>"},{"location":"#other-projects","title":"Other projects","text":"<p>TBC</p> <ul> <li> <p>flink_data_products includes a set of small data as a product examples implemented using Flink SQL. They are used to demonstrate pipeline management with shift_left tool and simplest use cases.</p> <ul> <li>the saleops is a simple example of Kimball structure for a star schema about revenu computation in the context of sales of products within different channels (See the readme for details). </li> </ul> </li> <li> <p>Ksql project: a set of files to be used for testing automatic migration from ksql.</p> </li> </ul> <p>To Be continued....</p>"},{"location":"c360/","title":"Customer 360 Analytics","text":""},{"location":"c360/#how-to-consume-this-content","title":"How to consume this content","text":"<p>The project is organized in two folds: </p> <ul> <li>a batch processing using Apache Sparks to build the customer_analytics_c360 data product</li> <li>real-time processing to build the same customer_analytics_c360 data product using Confluent Cloud Flink</li> </ul>"},{"location":"c360/#folder-structure","title":"Folder Structure","text":"<ul> <li>c360_* are a set of projects to demonstrate how to define a data as a product in Spark and its equivalent for real time processing in Flink SQL.</li> <li>c360_spark_processing a batch implementation using the <code>star schema</code> and Kimball method to organize facts, and dimensions. The project description is here.. This project was created using <code>shift_left project init c360_spark_processing</code> command.</li> <li>c360_mock_data: a set of CSV files to create synthetic data.</li> <li>c360_api: A Python FastAPI-based REST API that exposes Customer 360 analytics for Marketing, Product, and Finance teams built on top of Spark data pipeline.</li> <li>c360_flink_processing: Building the same analytic data as a product with Flink processing.</li> <li>Kafka_consumer: a cli based tool to consume the different topics from Kafka to validate the different results within the pipeline.</li> </ul>"},{"location":"c360/#to-do","title":"To Do","text":"<ul> <li> Kafka Producer to simulate injecting the data into raw topics</li> <li> Add tableflow in IaC for the customer_analytics_c360 topic to Iceberg table in AWS S3 or Confluent Storage.</li> <li> Python Flask App with a HTML dashboard to present the different data products from parquet files, using duckdb for query engine</li> <li> Be able to run the same SQLs on Confluent Platform for Flink.</li> </ul>"},{"location":"c360/data_models/","title":"Customer Analytics C360 Data Models","text":""},{"location":"c360/data_models/#overview","title":"Overview","text":"<p>This document defines the data models for the Customer 360 data product across four key business domains: </p> <ul> <li>Customer Domain: CRM, loyalty program, support tickets, app usage</li> <li>Sales Domain: Transactions, line items, regional sales  </li> <li>Product Domain: Catalog, inventory, suppliers, relationships</li> <li>Logistics Domain: Shipments, warehouses, tracking events</li> </ul>"},{"location":"c360/data_models/#1-customer-domain","title":"1. Customer Domain","text":"<ul> <li>Data Sources: CRM system, loyalty program, support tickets, app usage logs</li> <li>Data samples: c360_mock_data/customer</li> </ul>"},{"location":"c360/data_models/#tables","title":"Tables:","text":""},{"location":"c360/data_models/#customerscsv","title":"customers.csv","text":"Column Type Description customer_id STRING Unique customer identifier first_name STRING Customer first name last_name STRING Customer last name email STRING Customer email address phone STRING Customer phone number date_of_birth DATE Customer date of birth gender STRING Customer gender (M/F/O) registration_date TIMESTAMP When customer registered customer_segment STRING Customer segment (Premium, Standard, Basic) preferred_channel STRING Preferred shopping channel (online, store, mobile) address_line1 STRING Primary address city STRING City state STRING State/Province zip_code STRING ZIP/Postal code country STRING Country"},{"location":"c360/data_models/#loyalty_programcsv","title":"loyalty_program.csv","text":"Column Type Description customer_id STRING Foreign key to customers loyalty_tier STRING Loyalty tier (Bronze, Silver, Gold, Platinum) points_balance INTEGER Current loyalty points points_earned_ytd INTEGER Points earned year-to-date points_redeemed_ytd INTEGER Points redeemed year-to-date tier_start_date DATE When current tier was achieved lifetime_value DECIMAL(10,2) Customer lifetime value"},{"location":"c360/data_models/#support_ticketscsv","title":"support_tickets.csv","text":"Column Type Description ticket_id STRING Unique ticket identifier customer_id STRING Foreign key to customers created_date TIMESTAMP When ticket was created resolved_date TIMESTAMP When ticket was resolved category STRING Issue category (billing, product, shipping, etc.) priority STRING Priority level (low, medium, high, urgent) status STRING Current status (open, in_progress, resolved, closed) channel STRING Contact channel (phone, email, chat, store) satisfaction_score INTEGER Customer satisfaction (1-5)"},{"location":"c360/data_models/#app_usagecsv","title":"app_usage.csv","text":"Column Type Description usage_id STRING Unique usage record identifier customer_id STRING Foreign key to customers session_date DATE Date of app usage session_start TIMESTAMP Session start time session_duration_minutes INTEGER Session duration in minutes pages_viewed INTEGER Number of pages viewed actions_taken INTEGER Number of actions taken device_type STRING Device type (ios, android, web) app_version STRING App version used"},{"location":"c360/data_models/#2-sales-domain","title":"2. Sales Domain","text":"<ul> <li>Data Sources: Point of Sale (POS) system, e-commerce transactions, regional sales ledgers</li> <li>Data samples: c360_mock_data/sales</li> </ul>"},{"location":"c360/data_models/#tables_1","title":"Tables:","text":""},{"location":"c360/data_models/#transactionscsv","title":"transactions.csv","text":"Column Type Description transaction_id STRING Unique transaction identifier customer_id STRING Foreign key to customers transaction_date TIMESTAMP When transaction occurred channel STRING Sales channel (store, online, mobile) store_id STRING Store identifier (null for online) payment_method STRING Payment method used subtotal DECIMAL(10,2) Subtotal before tax/discounts tax_amount DECIMAL(10,2) Tax amount discount_amount DECIMAL(10,2) Discount applied total_amount DECIMAL(10,2) Final transaction total currency STRING Currency code status STRING Transaction status (completed, cancelled, refunded)"},{"location":"c360/data_models/#transaction_itemscsv","title":"transaction_items.csv","text":"Column Type Description item_id STRING Unique line item identifier transaction_id STRING Foreign key to transactions product_id STRING Foreign key to products quantity INTEGER Quantity purchased unit_price DECIMAL(10,2) Price per unit line_total DECIMAL(10,2) Total for this line item discount_applied DECIMAL(10,2) Discount on this item"},{"location":"c360/data_models/#regional_salescsv","title":"regional_sales.csv","text":"Column Type Description region_id STRING Unique region identifier region_name STRING Region name country STRING Country sales_date DATE Sales date total_revenue DECIMAL(12,2) Total revenue for region/date total_transactions INTEGER Number of transactions average_order_value DECIMAL(10,2) Average order value"},{"location":"c360/data_models/#3-product-domain","title":"3. Product Domain","text":"<ul> <li>Data Sources: Product catalog, inventory system, supplier data</li> <li>Data samples: c360_mock_data/products</li> </ul>"},{"location":"c360/data_models/#tables_2","title":"Tables:","text":""},{"location":"c360/data_models/#productscsv","title":"products.csv","text":"Column Type Description product_id STRING Unique product identifier product_name STRING Product name category STRING Product category subcategory STRING Product subcategory brand STRING Product brand price DECIMAL(10,2) Current price cost DECIMAL(10,2) Product cost weight_kg DECIMAL(8,3) Product weight in kg dimensions STRING Product dimensions color STRING Product color size STRING Product size created_date DATE When product was created status STRING Product status (active, discontinued, seasonal)"},{"location":"c360/data_models/#inventorycsv","title":"inventory.csv","text":"Column Type Description inventory_id STRING Unique inventory record identifier product_id STRING Foreign key to products location_id STRING Warehouse or store identifier stock_quantity INTEGER Current stock level reserved_quantity INTEGER Reserved stock reorder_point INTEGER Reorder threshold max_stock_level INTEGER Maximum stock level last_updated TIMESTAMP When record was last updated"},{"location":"c360/data_models/#supplierscsv","title":"suppliers.csv","text":"Column Type Description supplier_id STRING Unique supplier identifier supplier_name STRING Supplier company name contact_person STRING Primary contact email STRING Contact email phone STRING Contact phone address STRING Supplier address country STRING Supplier country payment_terms STRING Payment terms quality_rating DECIMAL(3,2) Quality rating (1.00-5.00)"},{"location":"c360/data_models/#product_supplierscsv","title":"product_suppliers.csv","text":"Column Type Description product_id STRING Foreign key to products supplier_id STRING Foreign key to suppliers is_primary BOOLEAN Is primary supplier for this product cost_price DECIMAL(10,2) Cost from this supplier lead_time_days INTEGER Lead time in days"},{"location":"c360/data_models/#4-logistics-domain","title":"4. Logistics Domain","text":"<ul> <li>Data Sources: Warehouse management, shipping manifests, tracking data</li> <li>Data samples: c360_mock_data/logistic</li> </ul>"},{"location":"c360/data_models/#tables_3","title":"Tables:","text":""},{"location":"c360/data_models/#shipmentscsv","title":"shipments.csv","text":"Column Type Description shipment_id STRING Unique shipment identifier transaction_id STRING Foreign key to transactions tracking_number STRING Carrier tracking number carrier STRING Shipping carrier service_level STRING Service level (standard, expedited, overnight) origin_location STRING Origin warehouse/store destination_address STRING Destination address weight_kg DECIMAL(8,3) Shipment weight dimensions STRING Package dimensions ship_date DATE Date shipped estimated_delivery DATE Estimated delivery date actual_delivery DATE Actual delivery date delivery_status STRING Current delivery status shipping_cost DECIMAL(8,2) Shipping cost"},{"location":"c360/data_models/#warehouse_locationscsv","title":"warehouse_locations.csv","text":"Column Type Description location_id STRING Unique location identifier location_name STRING Location name location_type STRING Type (warehouse, distribution_center, store) address STRING Full address city STRING City state STRING State/Province country STRING Country capacity_cubic_meters INTEGER Storage capacity manager_name STRING Location manager"},{"location":"c360/data_models/#tracking_eventscsv","title":"tracking_events.csv","text":"Column Type Description event_id STRING Unique event identifier shipment_id STRING Foreign key to shipments event_timestamp TIMESTAMP When event occurred event_type STRING Event type (picked_up, in_transit, out_for_delivery, delivered, etc.) location STRING Event location description STRING Event description carrier_status STRING Carrier's status code"},{"location":"c360/data_models/#data-relationships","title":"Data Relationships","text":""},{"location":"c360/data_models/#key-relationships","title":"Key Relationships:","text":"<ul> <li><code>customers.customer_id</code> \u2192 Primary key for customer dimension</li> <li><code>transactions.customer_id</code> \u2192 Links sales to customers</li> <li><code>transaction_items.product_id</code> \u2192 Links sales to products</li> <li><code>shipments.transaction_id</code> \u2192 Links logistics to sales</li> <li><code>inventory.product_id</code> \u2192 Links inventory to products</li> <li><code>product_suppliers.product_id</code> \u2192 Links suppliers to products</li> </ul>"},{"location":"c360/data_models/#c360-integration-points","title":"C360 Integration Points:","text":"<ul> <li>Customer Profile: Combine customers, loyalty_program, support_tickets, app_usage</li> <li>Purchase History: Join transactions with transaction_items and products  </li> <li>Fulfillment Data: Link shipments and tracking_events to customer orders</li> <li>Product Preferences: Analyze transaction_items to understand product affinity</li> </ul>"},{"location":"c360/data_models/#mock-data-generation","title":"Mock Data Generation","text":"<ul> <li>Location: <code>c360_mock_data/</code> directory</li> <li>Volume: 15 CSV files with realistic mock data</li> <li>Quality: Referential integrity maintained across domains</li> <li>Structure:   <pre><code>c360_mock_data/\n\u251c\u2500\u2500 customer/     (4 files: customers, loyalty, support, app usage)\n\u251c\u2500\u2500 sales/        (3 files: transactions, items, regional data)\n\u251c\u2500\u2500 products/     (4 files: products, inventory, suppliers, relationships)  \n\u2514\u2500\u2500 logistics/    (3 files: shipments, locations, tracking)\n</code></pre></li> </ul>"},{"location":"c360/flink_project/","title":"Customer 360 Flink Implementation","text":"<p>The Flink implementation is using the same approach as the spark implementation. The sources of data are now becoming streams, and to support the Stream capability we use Apache Kafka.</p> <p>This chapter proposes different approaches to implement the Flink SQL queries, one starting from a white page but using the shift Left Data Engineer's recipes. And one using AI to migrate from the Spark batch processing.</p>"},{"location":"c360/flink_project/#final-architecture","title":"Final architecture","text":"<p>The high level view of a star schema implementation with Flink looks like a set of statements and Kafka topics like in the following diagram:</p> <p></p> <p>The current approach for pure Confluent Cloud deployment the raw topics and raw data are created using SQL in the tests folder of each src_* tables.</p> <p>The final pipeline looks like in the following diagram and the consitency of the pipeline deployment is done with the shift_left tool:</p> <p></p>"},{"location":"c360/flink_project/#building-the-project","title":"Building the project","text":"<p>This section presents the commands executed to build the <code>c360_flink_processing</code> project, and all its content.</p>"},{"location":"c360/flink_project/#define-the-shift_left-utils-configuration","title":"Define the shift_left utils configuration","text":"<p>As the project uses the shift_left utils to define the project structure, the different tables, the pipelines, and the deployment, we need to do some configuration:</p> <ul> <li>Create a config.yaml from the template, and .gitignore it</li> <li>create a .env to export all the environment variables and .gitignore it</li> <li>source the .env</li> <li>Run: <code>shift_left project validate-config</code> -&gt; should get \"Config.yaml validated\" message</li> </ul>"},{"location":"c360/flink_project/#create-the-target-project","title":"Create the target project","text":"<p>It will create a <code>customer_360/c360_flink_processing</code> folder</p> <pre><code>shift_left project init c360_flink_processing customer_360\n</code></pre> <p>SQL files are organized into layers based on data processing stage:</p> <pre><code>sources/          \u2192 Load raw data\ndimensions/       \u2192 Reference tables\nintermediates/    \u2192 Transformations\nfacts/            \u2192 Aggregations\nviews/            \u2192 Final products\n</code></pre>"},{"location":"c360/flink_project/#add-table-foundations","title":"Add table foundations","text":"<ul> <li> <p>Create the fct_customer_360_profile <pre><code>shift_left table init fct_customer_360_profile $PIPELINES/facts --product-name c360\n</code></pre></p> <p>It should build the following structure: <pre><code>\u2514\u2500\u2500 c360\n    \u2514\u2500\u2500 fct_customer_360_profile\n        \u251c\u2500\u2500 Makefile\n        \u251c\u2500\u2500 sql-scripts\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.c360_fct_customer_360_profile.sql\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 dml.c360_fct_customer_360_profile.sql\n        \u251c\u2500\u2500 tests\n        \u2514\u2500\u2500 tracking.md\n</code></pre></p> <p>The DDL is created by looking as the expected structure in the corresponding Spark fct_customer_360_profile.sql</p> </li> </ul> <p>The fact needs source tables to get the data from raw topics.</p> <ul> <li> <p>Create  <code>src_loyalty_program</code> with the command:     <pre><code>shift_left table init src_loyalty_program $PIPELINES/sources --product-name c360\n</code></pre></p> </li> <li> <p>Other sources to create     <pre><code>shift_left table init src_customers  $PIPELINES/sources --product-name c360\nshift_left table init src_app_usage  $PIPELINES/sources --product-name c360\nshift_left table init src_support_ticket  $PIPELINES/sources --product-name c360\nshift_left table init src_tx_items  $PIPELINES/sources --product-name c360\n</code></pre></p> </li> <li>Each dml may implement the deduplication pattern.     <pre><code>insert into ..\nselect \n...\nFROM (\n    SELECT *,\n        ROW_NUMBER() OVER (\n            PARTITION BY ticket_id \n            ORDER BY `$rowtime` DESC\n        ) AS row_num\n    FROM support_ticket_raw\n) WHERE row_num = 1\n</code></pre></li> <li>for each sources add the creation of the raw tables, and the insert statements to get some values into the raw kafka topics. Use the following prompt to the AI code assistant:     <pre><code>create a flink sql to insert the same records from the @support_tickets.csv into a support_ticket_raw\n</code></pre></li> </ul>"},{"location":"c360/flink_project/#add-an-intermediate-table-for-the-transaction","title":"Add an intermediate table for the transaction","text":"<pre><code>shift_left table init int_customer_transactions  $PIPELINES/intermediates --product-name c360\n</code></pre> <p>which leads to create new srcs and raws <pre><code>shift_left table init src_tx_items  $PIPELINES/sources --product-name c360\nshift_left table init src_transactions  $PIPELINES/sources --product-name c360 \nshift_left table init src_products  $PIPELINES/sources --product-name c360\n</code></pre></p> <p>One of the prompt is: <pre><code>create a flink sql to insert the same records from the @transaction_items.csv into insert transaction_items_raw\n</code></pre></p> <p>At that stage the files and folders constructed are (removing Makefile and tracking.md): <pre><code>\u251c\u2500\u2500 dimensions\n\u251c\u2500\u2500 facts\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 c360\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 fct_customer_360_profile\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 sql-scripts\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.c360_fct_customer_profile.sql\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0 \u2514\u2500\u2500 dml.c360_fct_customer_profile.sql\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 tests\n\u251c\u2500\u2500 intermediates\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 c360\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 int_customer_transactions\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 sql-scripts\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.int_c360_customer_transactions.sql\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0 \u2514\u2500\u2500 dml.int_c360_customer_transactions.sql\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 tests\n\u251c\u2500\u2500 sources\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 c360\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 src_app_usage\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 sql-scripts\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.src_c360_app_usage.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 dml.src_c360_app_usage.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 tests\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.app_usage_raw.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 insert_app_usage_raw.sql\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 src_customers\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 sql-scripts\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.src_c360_customers.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 dml.src_c360_customers.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 tests\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.customers_raw.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 insert_customers_raw.sql\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 src_loyalty_program\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 sql-scripts\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.src_c360_loyalty_program.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 dml.src_c360_loyalty_program.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 tests\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.loyalty_program_raw.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 insert_loyalty_program_raw.sql\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 src_products\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 sql-scripts\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.src_c360_products.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 dml.src_c360_products.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 tests\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.product_raw.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 insert_product_raw.sql\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 src_support_ticket\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 sql-scripts\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.src_c360_support_ticket.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 dml.src_c360_support_ticket.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 tests\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.support_ticket_raw.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 insert_support_ticket_raw.sql\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 src_transactions\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 sql-scripts\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.src_c360_transactions.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 dml.src_c360_transactions.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 tests\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.tx_raw.sql\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 insert_tx_raw.sql\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 src_tx_items\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 sql-scripts\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.src_c360_tx_items.sql\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0 \u2514\u2500\u2500 dml.src_c360_tx_items.sql\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 tests\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.tx_items_raw.sql\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0 \u2514\u2500\u2500 insert_tx_items_raw.sql\n</code></pre></p>"},{"location":"c360/flink_project/#build-the-views-as-gold-layer","title":"Build the views as gold layer","text":"<pre><code>shift_left table init customer_analytics_c360 $PIPELINES/views --product-name c360\n</code></pre> <p>The tree is now:</p> <pre><code>views\n\u2514\u2500\u2500 c360\n    \u2514\u2500\u2500 customer_analytics_c360\n        \u251c\u2500\u2500 sql-scripts\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 ddl.customer_analytics_c360.sql\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 dml.customer_analytics_c360.sql\n        \u251c\u2500\u2500 tests\n</code></pre> <p>See the views/c360/customer_analytics_c360/sql-scripts/dml.customer_analytics_c360.sql</p>"},{"location":"c360/flink_project/#finalize-the-fact-tables","title":"Finalize the Fact tables","text":"<p>This is mostly to verify the column types and the logic of the dml that matches the Spark SQL. See the facts/c360/fct_customer_360_profile/sql-scripts/dml.c360_fct_customer_profile.sql</p>"},{"location":"c360/flink_project/#using-shift_left-tools-to-manage-the-pipeline","title":"Using Shift_left tools to manage the pipeline","text":"<ol> <li>Build the table inventory     <pre><code>shift_left table build-inventory\n</code></pre></li> <li>Build all the table metadata     <pre><code>shift_left  pipeline build-all-metadata\n</code></pre></li> <li> <p>Verify the execution plan for the view table     <pre><code> shift_left pipeline build-execution-plan --table-name customer_analytics_c360 --compute-pool-id lfcp-xvr...z\n</code></pre></p> <p><pre><code>--- Ancestors: 9 ---\nStatement Name                                                  Status          Compute Pool    Action  Upgrade Mode    Table Name\n-----------------------------------------------------------------------------------------------------------------------------------------------------------\ndev-usw2-c360-dml-src-c360-loyalty-program                      UNKNOWN         lfcp-xvrvmz     To run  Stateless       src_c360_loyalty_program\ndev-usw2-c360-dml-src-c360-app-usage                            UNKNOWN         lfcp-xvrvmz     To run  Stateful        src_c360_app_usage\ndev-usw2-c360-dml-src-c360-customers                            UNKNOWN         lfcp-xvrvmz     To run  Stateful        src_c360_customers\ndev-usw2-c360-dml-src-c360-support-ticket                       UNKNOWN         lfcp-xvrvmz     To run  Stateful        src_c360_support_ticket\ndev-usw2-c360-dml-src-c360-transactions                         UNKNOWN         lfcp-xvrvmz     To run  Stateless       src_c360_transactions\ndev-usw2-c360-dml-src-c360-tx-items                             UNKNOWN         lfcp-xvrvmz     To run  Stateful        src_c360_tx_items\ndev-usw2-c360-dml-src-c360-products                             UNKNOWN         lfcp-xvrvmz     To run  Stateless       src_c360_products\ndev-usw2-c360-dml-int-c360-customer-transactions                UNKNOWN         lfcp-xvrvmz     To run  Stateful        int_c360_customer_transactions\ndev-usw2-c360-dml-c360-fct-customer-profile                     UNKNOWN         lfcp-xvrvmz     To run  Stateful        c360_fct_customer_profile\n\n--- Children to restart ---\nStatement Name                                                  Status          Compute Pool    Action  Upgrade Mode    Table Name\n-----------------------------------------------------------------------------------------------------------------------------------------------------------\ndev-usw2-c360-dml-customer-analytics-c360                       UNKNOWN         lfcp-xvrvmz     Restart Stateless       customer_analytics_c360\n</code></pre> 1. Verify the execution plan for the c360 product <pre><code> shift_left pipeline build-execution-plan --product-name c360 --compute-pool-id lfcp-x...z\n</code></pre></p> </li> <li> <p>Perform the deployment in sequential mode     <pre><code>shift_left pipeline deploy --product-name c360 --compute-pool-id lfcp-x...z\n</code></pre></p> <p>The trace may includes</p> <pre><code>20251105_19:22:29 Execute for customer_analytics_c360 started. 10 statements to execute\n20251105_19:22:29 Still 10 statements to execute\n20251105_19:22:29 Deploy table src_c360_customers\n20251105_19:22:45 Still 9 statements to execute\n20251105_19:22:45 Deploy table src_c360_support_ticket\n20251105_19:23:21 DML deployment completed for src_c360_support_ticket\n20251105_19:23:21 Still 8 statements to execute\n20251105_19:23:21 Deploy table src_c360_app_usage\n20251105_19:23:39 DML deployment completed for src_c360_app_usage\n20251105_19:23:39 Still 7 statements to execute\n20251105_19:23:39 Deploy table src_c360_loyalty_program\n20251105_19:23:56 DML deployment completed for src_c360_loyalty_program\n20251105_19:23:56 Still 6 statements to execute\n20251105_19:23:56 Deploy table src_c360_products\n20251105_19:24:03 Still 5 statements to execute\n20251105_19:24:03 Deploy table src_c360_tx_items\n20251105_19:24:21 DML deployment completed for src_c360_tx_items\n20251105_19:24:21 Still 4 statements to execute\n20251105_19:24:21 Deploy table src_c360_transactions\n20251105_19:24:27 Still 3 statements to execute\n20251105_19:24:27 Deploy table int_c360_customer_transactions\n20251105_19:24:30 Load current flink statements using REST API 49cee212-6346-438a-a1fa-d1b1cbd90d44\n20251105_19:24:31 Statement list has 188 statements\nWait dev-usw2-c360-dml-int-c360-customer-transactions deployment, increase wait response timer to 20 seconds\n20251105_19:25:06 DML deployment completed for int_c360_customer_transactions\n20251105_19:25:06 Still 2 statements to execute\n20251105_19:25:06 Deploy table c360_fct_customer_profile\n</code></pre> </li> </ol>"},{"location":"c360/flink_project/#shifting-left-from-batch-to-real-time","title":"Shifting left from batch to real-time","text":"<p>As illustrated by the Spark project, the analytical data prduct is accessible after each batch pipeline execution, and even a REST API needs to run the spark job, and then cache the results for a certain time to deliver the data product via its interface.</p> <p>As introduced by the Spark to Flink SQL migration section it is possible to migrate with a local LLM.</p> <ul> <li> <p>Start Ollama server     <pre><code>ollama serve\n</code></pre></p> </li> <li> <p>Try a migration     <pre><code>shift_left table migrate fct_customer_360_profile $SRC_FOLDER/facts/fct_customer_360_profile.sql $STAGING --source-type spark\n</code></pre></p> </li> </ul>"},{"location":"c360/spark_project/","title":"Customer 360 Spark Implementation","text":"<p>The Spark implementation for the Customer 360 analytics uses the Kimball methodology of Sources \u2192 Intermediates \u2192 Facts \u2192 Views.</p> <p>The demonstration supports a Customer 360 (C360) data product for a multi-channel retailer, following the data product architecture outlined in the design document. The project implements a complete data pipeline from mock data generation to final consumable analytics views.</p> <p>The spark-sql creates a Hive metastore to contain the persistent view definitions and the database schema metadata.</p> <p>As an analytical pipeline, the sources are processed at each spark session, on-demand, and there is no persistence of the computed results.</p>"},{"location":"c360/spark_project/#key-features","title":"Key Features","text":"<p>The implemented pipeline creates a comprehensive customer view for analytics, BI, and ML initiatives. The name of this data product is <code>customer_analytics_c360</code>.</p>"},{"location":"c360/spark_project/#data-pipeline-flow","title":"Data Pipeline Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    run_c360_pipeline.sh                     \u2502\n\u2502                                                             \u2502\n\u2502  [--separate-sessions flag determines execution mode]       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502  Execution Mode Decision           \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u25bc                               \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 Single Session  \u2502             \u2502 Separate        \u2502\n    \u2502 (Default)       \u2502             \u2502 Sessions        \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502                               \u2502\n              \u2502                               \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 Combine all SQL   \u2502         \u2502 Run each layer in   \u2502\n    \u2502 into temp file    \u2502         \u2502 separate spark-sql  \u2502\n    \u2502 \u2192 Single spark-sql\u2502         \u2502 sessions            \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502                               \u2502\n              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u25bc\n                    Execute Layers in Order\n</code></pre>"},{"location":"c360/spark_project/#layer-by-layer-data-flow","title":"Layer-by-Layer Data Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  LAYER 1: SOURCES                                                \u2502\n\u2502  Load raw data from CSV files                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502    src_customers.sql                                             \u2502\n\u2502     ../c360_mock_data/customer/customers.csv                     \u2502\n\u2502     \u2193                                                            \u2502\n\u2502     customers_raw \u2192 src_customers (view)                         \u2502\n\u2502                                                                  \u2502\n\u2502    src_loyalty_program.sql                                       \u2502\n\u2502     ../c360_mock_data/customer/loyalty_program.csv               \u2502\n\u2502     \u2193                                                            \u2502\n\u2502     loyalty_program_raw \u2192 src_loyalty_program (view)             \u2502\n\u2502                                                                  \u2502\n\u2502    src_products.sql                                              \u2502\n\u2502     ../c360_mock_data/products/products.csv                      \u2502\n\u2502     \u2193                                                            \u2502\n\u2502     products_raw \u2192 src_products (view)                           \u2502\n\u2502                                                                  \u2502\n\u2502    src_transactions.sql                                          \u2502\n\u2502     ../c360_mock_data/sales/transactions.csv                     \u2502\n\u2502     \u2193                                                            \u2502\n\u2502     transactions_raw \u2192 src_transactions (view)                   \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  LAYER 2: DIMENSIONS                                             \u2502\n\u2502  Reference/lookup tables (optional, currently empty)             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502  (No files yet - placeholder for future dimension tables)        \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  LAYER 3: INTERMEDIATES                                          \u2502\n\u2502  Join and enrich data across sources                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502   int_customer_transactions.sql                                  \u2502\n\u2502     DEPENDS ON:                                                  \u2502\n\u2502       - src_customers                                            \u2502\n\u2502       - src_transactions                                         \u2502\n\u2502       - src_products                                             \u2502\n\u2502       - transaction_items_raw (loaded inline)                    \u2502\n\u2502     \u2193                                                            \u2502\n\u2502     Combines customer + transaction + product data               \u2502\n\u2502     \u2193                                                            \u2502\n\u2502     int_customer_transactions (view)                             \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  LAYER 4: FACTS                                                  \u2502\n\u2502  Aggregate metrics and KPIs                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502   fct_customer_360_profile.sql                                   \u2502\n\u2502     DEPENDS ON:                                                  \u2502\n\u2502       - src_customers                                            \u2502\n\u2502       - src_loyalty_program                                      \u2502\n\u2502       - int_customer_transactions                                \u2502\n\u2502       - support_tickets_raw (loaded inline)                      \u2502\n\u2502       - app_usage_raw (loaded inline)                            \u2502\n\u2502     \u2193                                                            \u2502\n\u2502     Aggregates all customer metrics:                             \u2502\n\u2502       \u2022 Transaction summaries                                    \u2502\n\u2502       \u2022 Support ticket metrics                                   \u2502\n\u2502       \u2022 App usage statistics                                     \u2502\n\u2502       \u2022 RFM scores (Recency, Frequency, Monetary)                \u2502\n\u2502     \u2193                                                            \u2502\n\u2502     fct_customer_360_profile (view)                              \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  LAYER 5: VIEWS                                                  \u2502\n\u2502  Final consumable data products                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502   customer_analytics_c360.sql                                    \u2502\n\u2502     DEPENDS ON:                                                  \u2502\n\u2502       - fct_customer_360_profile                                 \u2502\n\u2502     \u2193                                                            \u2502\n\u2502     Applies:                                                     \u2502\n\u2502       \u2022 Data quality filters                                     \u2502\n\u2502       \u2022 Business logic (customer health score)                   \u2502\n\u2502       \u2022 Risk indicators (churn risk, satisfaction risk)          \u2502\n\u2502       \u2022 Opportunity flags (upsell, cross-sell)                   \u2502\n\u2502     \u2193                                                            \u2502\n\u2502     customer_analytics_c360 (view) FINAL DATA PRODUCT            \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u2502   Validation Queries      \u2502\n              \u2502   \u2022 Total customers       \u2502\n              \u2502   \u2022 Total revenue         \u2502\n              \u2502   \u2022 Active customers      \u2502\n              \u2502   \u2022 At-risk customers     \u2502\n              \u2502   \u2022 Sample records        \u2502\n              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"c360/spark_project/#single-session-vs-separate-sessions","title":"Single Session vs Separate Sessions","text":""},{"location":"c360/spark_project/#single-session-mode-default","title":"Single Session Mode (Default)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  One Spark Session                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502 Execute sources/*.sql              \u2502     \u2502\n\u2502  \u2502 \u2193                                  \u2502     \u2502\n\u2502  \u2502 Execute dimensions/*.sql           \u2502     \u2502\n\u2502  \u2502 \u2193                                  \u2502     \u2502\n\u2502  \u2502 Execute intermediates/*.sql        \u2502     \u2502\n\u2502  \u2502 \u2193                                  \u2502     \u2502\n\u2502  \u2502 Execute facts/*.sql                \u2502     \u2502\n\u2502  \u2502 \u2193                                  \u2502     \u2502\n\u2502  \u2502 Execute views/*.sql                \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"c360/spark_project/#separate-sessions-mode","title":"Separate Sessions Mode","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Session 1                                  \u2502\n\u2502  \u2514\u2500 Execute sources/*.sql                   \u2502\n\u2502     \u2514\u2500 Exit session                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Session 2                                  \u2502\n\u2502  \u2514\u2500 Execute dimensions/*.sql                \u2502\n\u2502     \u2514\u2500 Exit session                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Session 3                                  \u2502\n\u2502  \u2514\u2500 Execute intermediates/*.sql             \u2502\n\u2502     \u2514\u2500 Exit session                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Session 4                                  \u2502\n\u2502  \u2514\u2500 Execute facts/*.sql                     \u2502\n\u2502     \u2514\u2500 Exit session                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Session 5                                  \u2502\n\u2502  \u2514\u2500 Execute views/*.sql                     \u2502\n\u2502     \u2514\u2500 Exit session                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"c360/spark_project/#key-concepts","title":"Key Concepts","text":""},{"location":"c360/spark_project/#view-persistence","title":"View Persistence","text":"<ul> <li>Temporary Views: Created with <code>CREATE OR REPLACE TEMPORARY VIEW</code></li> <li>Only exist within the Spark session</li> <li>Perfect for pipeline transformations</li> <li>Don't pollute the metastore</li> </ul>"},{"location":"c360/spark_project/#execution-order","title":"Execution Order","text":"<ul> <li>Layers execute in dependency order: Sources \u2192 Dimensions \u2192 Intermediates \u2192 Facts \u2192 Views</li> <li>Within each layer, files execute alphabetically</li> <li>Use numeric prefixes to control order: <code>01_</code>, <code>02_</code>, etc.</li> </ul>"},{"location":"c360/spark_project/#error-handling","title":"Error Handling","text":"<ul> <li>Script exits on first error (<code>set -e</code>)</li> <li>In single session mode: Debug file preserved on error</li> <li>In separate sessions mode: Each layer isolated for easier debugging</li> </ul>"},{"location":"c360/spark_project/#auto-discovery","title":"Auto-Discovery","text":"<ul> <li>Script uses <code>find</code> to discover all <code>.sql</code> files</li> <li>No hard-coded file names</li> <li>Add/remove files freely - no script changes needed</li> </ul> <p>Ready to explore? Run <code>./run_c360_pipeline.sh</code> and watch the data flow through the layers!</p>"},{"location":"c360/spark_project/#customer-health-scoring","title":"Customer Health Scoring","text":"<p>The following KPIs may be defined.</p>"},{"location":"c360/spark_project/#rfm-analysis-health-scoring","title":"RFM Analysis &amp; Health Scoring","text":"<ul> <li>Recency Score (1-5): Based on last purchase date</li> <li>Frequency Score (1-5): Based on transaction count  </li> <li>Monetary Score (1-5): Based on total spending</li> <li>Customer Health Score: Composite metric for overall value</li> </ul>"},{"location":"c360/spark_project/#customer-status-classification","title":"Customer Status Classification","text":"<ul> <li>Active: Recent purchases (\u226430 days)</li> <li>At Risk: Moderate inactivity (31-90 days)</li> <li>Churned: Extended inactivity (&gt;90 days)</li> <li>Never Purchased: No transaction history</li> </ul>"},{"location":"c360/spark_project/#cross-domain-integration","title":"Cross-Domain Integration","text":"<ul> <li>Demographics: Age, generation, location, tenure</li> <li>Loyalty Program: Tier, points, lifetime value</li> <li>Purchase Behavior: Channels, frequency, preferences</li> <li>Support Interaction: Tickets, satisfaction, issues</li> <li>Digital Engagement: App usage, device types, engagement score</li> </ul>"},{"location":"c360/spark_project/#risk-opportunity-identification","title":"Risk &amp; Opportunity Identification","text":"<ul> <li>Churn Risk Flags: Based on activity and satisfaction</li> <li>Channel Expansion: Single-channel customers with growth potential</li> <li>Tier Upgrade: High-value customers in lower tiers</li> <li>App Adoption: Active customers not using digital channels</li> </ul>"},{"location":"c360/spark_project/#components","title":"Components","text":"<ul> <li>4 Source files: Raw data ingestion with enrichment</li> <li>1 Intermediate file: Customer-transaction integration layer</li> <li>1 Fact table: Complete customer profile with metrics</li> <li>1 Final view: Consumable data product</li> </ul>"},{"location":"c360/spark_project/#key-sql-files","title":"Key SQL Files","text":""},{"location":"c360/spark_project/#sources","title":"Sources","text":"<ul> <li><code>src_customers.sql</code> - Customer demographics with derived fields read from the raw_customers.</li> <li><code>src_loyalty_program.sql</code> - Loyalty data with tier analysis read from loyalty_program_raw</li> <li><code>src_transactions.sql</code> - Sales data with time-based enrichment read from transactions_raw</li> <li><code>src_products.sql</code> - Product catalog with category groupings read from products_raw</li> </ul>"},{"location":"c360/spark_project/#intermediates","title":"Intermediates","text":"<ul> <li><code>int_customer_transactions.sql</code> - Joined customer-transaction data</li> </ul>"},{"location":"c360/spark_project/#facts","title":"Facts","text":"<ul> <li><code>fct_customer_360_profile.sql</code> - Complete customer profile with metrics</li> </ul>"},{"location":"c360/spark_project/#views","title":"Views","text":"<ul> <li><code>customer_analytics_c360.sql</code> - Final data product for consumption</li> </ul>"},{"location":"c360/spark_project/#data-lineage","title":"Data Lineage","text":"<pre><code>Raw CSV Files\n    \u2502\n    \u251c\u2500\u2500 customers.csv \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u251c\u2500\u2500 loyalty_program.csv \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u251c\u2500\u2500 products.csv \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u251c\u2500\u2500 transactions.csv \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u251c\u2500\u2500 transaction_items.csv \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u251c\u2500\u2500 support_tickets.csv \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2514\u2500\u2500 app_usage.csv \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                      \u2502\n                                      \u25bc\n                            Source Views (Layer 1)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 src_customers                             \u2502\n    \u2502 src_loyalty_program                       \u2502\n    \u2502 src_products                              \u2502\n    \u2502 src_transactions                          \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u25bc\n            Intermediate Views (Layer 3)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 int_customer_transactions                 \u2502\n    \u2502   (combines customers + transactions +    \u2502\n    \u2502    products + transaction items)          \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u25bc\n                Fact Tables (Layer 4)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 fct_customer_360_profile                  \u2502\n    \u2502   (aggregates all metrics:                \u2502\n    \u2502    transactions, support, app usage,      \u2502\n    \u2502    loyalty, RFM scores)                   \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u25bc\n            Final Data Product (Layer 5)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 customer_analytics_c360                   \u2502\n    \u2502   (filtered, enriched, with business      \u2502\n    \u2502    rules and data quality checks)         \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u25bc\n            Business Intelligence\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 \u2022 Dashboards (Tableau, Power BI)          \u2502\n    \u2502 \u2022 Reports (Customer health, churn)        \u2502\n    \u2502 \u2022 ML Models (Churn prediction)            \u2502\n    \u2502 \u2022 Operational queries (CRM, marketing)    \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"c360/spark_project/#demonstration","title":"Demonstration","text":""},{"location":"c360/spark_project/#prerequisites","title":"Prerequisites","text":"<ul> <li>Apache Spark 3.x installed with <code>spark-sql</code> command available: <code>brew install apache-spark</code></li> <li>Mock CSV data in <code>../c360_mock_data/</code> directory</li> </ul>"},{"location":"c360/spark_project/#step-by-step-execution","title":"Step by step execution","text":"<p>The following commands execute the pipeline step by step so we can understand the processing logic.</p> <pre><code># 0. start the shell in the c360_spark_processing\nspark-sql\n# 1. Load source views\nsource sources/src_customers.sql;\nselect * from src_customers;\nsource sources/src_loyalty_program.sql;\nselect * from src_loyalty_program;\nsource sources/src_transactions.sql;\nselect * from src_transactions;\nsource sources/src_products.sql;\nselect * from src_products;\n\n# 2. Verify tables\nshow tables;\ncustomers_raw\nloyalty_program_raw\nproducts_raw\nsrc_customers\nsrc_loyalty_program\nsrc_products\nsrc_transactions\ntransactions_raw\n\n# 3. Create intermediate views\nsource intermediates/int_customer_transactions.sql;\nselect * from int_customer_transactions;\n\n# 4. Build fact tables\nsource facts/fct_customer_360_profile.sql;\nselect * from fct_customer_360_profile;\n\n# 5. Create final data product view\nsource views/customer_analytics_c360.sql;\n\n# 6. Query the data product\nSELECT * FROM customer_analytics_c360 LIMIT 10;\n</code></pre> <p>The completion of this pipeline creates a <code>metastore_db</code> folder which is a Apache Spark's embedded Hive metastore database.</p> <p>The Hive Metastore stores metadata about databases, tables, views, and schemas. There is also a Derby Database used as the embedded database engine.</p>"},{"location":"c360/spark_project/#expected-results","title":"Expected Results","text":"<p>After successful execution, you'll see:</p> <ul> <li>15 customers processed from mock data</li> <li>Pipeline Summary showing customer distribution</li> <li>Top 5 customers by health score</li> <li>All customers currently show \"Churned\" status (expected - mock data is from May/June 2024)</li> </ul> <p>Sample output:</p> <pre><code>Pipeline Summary: 15 total customers, 0 active, 15 at risk, 1.87 avg health score\nTop Customer: Lisa Anderson (CUST009) - Platinum tier, $1019.98 spent, 2.67 health score\n</code></pre>"},{"location":"c360/spark_project/#quick-execution","title":"Quick Execution","text":""},{"location":"c360/spark_project/#run-complete-pipeline-recommended","title":"Run Complete Pipeline (Recommended)","text":"<pre><code>cd c360_spark_processing\n./run_c360_pipeline.sh\n</code></pre>"},{"location":"c360/spark_project/#run-consolidated-sql-directly","title":"Run Consolidated SQL Directly","text":"<pre><code>cd c360_spark_processing  \nspark-sql -f c360_consolidated_pipeline.sql\n</code></pre>"},{"location":"c360/spark_project/#usage-examples","title":"Usage Examples","text":"<p>From this customer analytics data product it is possible to extract some specific analytic metrics:</p>"},{"location":"c360/spark_project/#sample-customer-360-profile","title":"Sample Customer 360 Profile","text":"<pre><code>SELECT \n    customer_id,\n    first_name || ' ' || last_name as customer_name,\n    customer_segment,          -- Premium, Standard, Basic\n    loyalty_tier,             -- Platinum, Gold, Silver, Bronze\n    customer_status,          -- Active, At Risk, Churned\n    total_transactions,       -- Purchase frequency\n    total_spent,             -- Total lifetime spending\n    customer_health_score,   -- Composite RFM score (1-5)\n    churn_risk_flag,         -- Risk indicator\n    app_engagement_score     -- Digital engagement metric\nFROM customer_analytics_c360;\n</code></pre>"},{"location":"c360/spark_project/#marketing-use-cases","title":"Marketing Use Cases","text":"<pre><code>-- Identify churn risk customers \nSELECT customer_id, first_name, last_name, customer_health_score\nFROM customer_analytics_c360 \nWHERE churn_risk_flag = 1 \n  AND lifetime_value &gt; 1000;\n\n-- Segment customers by generation for targeted messaging\nSELECT generation_segment, \n       COUNT(*) as customer_count,\n       AVG(lifetime_value) as avg_ltv\nFROM customer_analytics_c360 \nGROUP BY generation_segment;\n</code></pre>"},{"location":"c360/spark_project/#product-analysis","title":"Product Analysis","text":"<pre><code>-- Analyze channel expansion opportunities\nSELECT preferred_channel,\n       COUNT(*) as customers,\n       SUM(channel_expansion_opportunity) as expansion_opps\nFROM customer_analytics_c360\nGROUP BY preferred_channel;\n</code></pre>"},{"location":"c360/spark_project/#finance-analysis","title":"Finance Analysis","text":"<pre><code>-- Customer lifetime value by segment\nSELECT value_segment,\n       COUNT(*) as customers,\n       AVG(lifetime_value) as avg_ltv,\n       SUM(total_spent) as total_revenue\nFROM customer_analytics_c360\nGROUP BY value_segment;\n</code></pre>"},{"location":"c360/spark_project/#data-quality","title":"Data Quality","text":""},{"location":"c360/spark_project/#validation-rules","title":"Validation Rules","text":"<ul> <li>Customer ID must be present and unique</li> <li>Email addresses must be non-null and non-empty</li> <li>Transaction amounts must be positive</li> <li>Dates must be valid and reasonable</li> </ul>"},{"location":"c360/spark_project/#data-completeness","title":"Data Completeness","text":"<ul> <li>Customer data: 100% on key demographics</li> <li>Transaction data: 95%+ on purchase history</li> <li>Support data: Variable based on customer interaction</li> <li>App usage: Available for digital customers only</li> </ul>"},{"location":"c360/spark_project/#performance-considerations","title":"Performance Considerations","text":""},{"location":"c360/spark_project/#optimization-strategies","title":"Optimization Strategies","text":"<ul> <li>Partition by customer_id for efficient queries</li> <li>Index on frequently queried dimensions (customer_segment, loyalty_tier)</li> <li>Cache intermediate results for iterative analysis</li> <li>Use columnar storage (Parquet) for analytical workloads</li> </ul>"},{"location":"c360/spark_project/#scaling","title":"Scaling","text":"<ul> <li>Designed to handle millions of customers</li> <li>Horizontal scaling via Spark cluster</li> <li>Incremental processing for large datasets</li> <li>Real-time streaming integration capability</li> </ul>"},{"location":"c360/spark_project/#integration-points","title":"Integration Points","text":""},{"location":"c360/spark_project/#consuming-systems","title":"Consuming Systems","text":"<ul> <li>BI Tools: Tableau, Power BI, Looker</li> <li>ML Platforms: MLflow, PyTorsh, Notebook.</li> </ul>"},{"location":"c360/spark_project/#api-access","title":"API Access","text":"<pre><code># Python example for programmatic access\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName(\"C360Analysis\").getOrCreate()\nc360_df = spark.sql(\"SELECT * FROM customer_analytics_c360\")\nhigh_value_customers = c360_df.filter(\"customer_health_score &gt;= 4.0\")\n</code></pre>"}]}