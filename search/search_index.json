{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Flink Project Demonstrations","text":"<p>This project includes one Spark project to illustrate batch processing to build a customer 360 analytic data product. The high level architecture of this demonstration is:</p> <p></p> <p>From this project we will shift left by moving the batch-based Spark processing to a real-time processing with Kafka and Flink project:</p> <p></p> <p>The project also demonstrates an automatic migration from Spark to Flink using the shift_left tool and agentic AI.</p> <p>Finally other Flink projects are also includes to demonstrate smaller use cases.</p>"},{"location":"#a-data-as-a-product-design","title":"A data as a product design","text":"<p>The specific use case is a multi-channel retailer (bricks-and-mortar stores, e-commerce, mobile app) migrating their analytics platform to an Analytics Lakehouse with real-time processing.</p> <p>The project identifies the key business domains and assigning the following ownership:</p> Domain Data Owner/Team Key Data Sources Customer Customer Experience/CRM Team CRM system, loyalty program, support tickets, app usage logs Sales Finance/Sales Operations Team Point of Sale (POS) system, e-commerce transactions, regional sales ledgers Product Merchandising Team Product catalog, inventory system, supplier data Logistics Supply Chain Team Warehouse management, shipping manifests, tracking data <p>The Customer Domain Team is responsible for building a core data product named, the Customer 360 Data Product.</p> Metadata Description Product Name: customer.analytics.C360 Purpose: To provide a comprehensive, high-quality, and up-to-date view of a customer for analytics, BI, and ML initiatives across all other domains. Data Storage: Uses the Lakehouse's object storage in an open format (e.g. Iceberg tables) for ACID-compliant, performant data. Ingestion: Real-time are managed by the Customer Domain Team to ingest and transform raw data from source systems into the Lakehouse."},{"location":"#data-product-output","title":"Data Product Output:","text":"<p>The final curated data is exposed via well-defined, easily consumable interfaces: </p> <ul> <li>SQL Endpoint: A materialized view or table on the Lakehouse that other domains can query directly using SQL.</li> <li>API Service: A REST API for low-latency, record-by-record lookups (e.g., for a personalized recommendation service).</li> <li>File Export: Secure, versioned file exports for large-scale ML model training.</li> </ul>"},{"location":"#data-product-characteristics","title":"Data Product Characteristics:","text":"<ul> <li>Discoverable: Registered in a central Data Catalog (a self-service component of the Mesh).</li> <li>Addressable: Has a unique identifier and clear documentation (customer.analytics.C360).</li> <li>Trustworthy: Includes built-in data quality checks (DQ) and validation rules enforced by the Customer Team.</li> <li>Self-Describing: Contains rich, up-to-date metadata (schema, lineage, ownership, DQ metrics).</li> <li>Secure &amp; Governed: Access is controlled using federated governance rules (e.g., fine-grained, tag-based access control on the Lakehouse).</li> </ul>"},{"location":"#cross-domain-consumption-for-analytics","title":"Cross-Domain Consumption for Analytics","text":"<p>Other domains then consume this product to achieve their analytical goals:</p> Consuming Domain Analytical Goal Data Product Consumed Marketing Predict churn for a targeted email campaign. customer.analytics.Customer360Profile (to get demographics, loyalty score, purchase history). Product Analyze which customer segments are buying a new line of shoes. customer.analytics.Customer360Profile joined with the Sales Domain's sales.transaction.AggregatedDailySales product. Finance Calculate the Customer Lifetime Value (CLV) Queries the customer.analytics.Customer360Profile via the SQL endpoint. <p>To read more about moving from DDD to Data as a product methodology see this chapter.</p>"},{"location":"#flink-project-demos-folder-structure","title":"Flink Project Demos - Folder Structure","text":"<ul> <li>c360_* are a set of projects to demonstrate how to define a data as a product in Spark and its equivalent for real time processing in Flink SQL.<ul> <li>c360_spark_processing a batch implementation using the <code>star schema</code> and Kimball method to organize facts, and dimensions. The project description is here.. This project was created using <code>shift_left project init c360_spark_processing</code> command.</li> <li>c360_mock_data: a set of CSV files to create synthetic data.</li> <li>c360_api: A FastAPI-based REST API that exposes Customer 360 analytics for Marketing, Product, and Finance teams built on top of Spark data pipeline.</li> <li>c360_flink_processing: Building the same data as a product with Flink processing.</li> </ul> </li> <li> <p>flink_data_products includes a set of small data as a product examples implemented using Flink SQL. They are used to demonstrate pipeline management with shift_left tool and simplest use cases.</p> <ul> <li>the saleops is a simple example of Kimball structure for a star schema about revenu computation in the context of sales of products within different channels (See the readme for details). </li> </ul> </li> <li> <p>Ksql project: a set of files to be used for testing automatic migration from ksql.</p> </li> </ul> <p>To Be continued....</p>"},{"location":"automatic_migration/","title":"Shifting left from batch to real-time","text":"<p>As illustrated by the Spark project, the analytical data prduct is accessible after each batch pipeline execution, and even a REST API needs to run the spark job, and then cache the result for a certain time.</p> <p>The goal is to move to close to real-time processing.</p>"},{"location":"c360/data_models/","title":"Customer Analytics C360 Data Models","text":""},{"location":"c360/data_models/#overview","title":"Overview","text":"<p>This document defines the data models for the Customer 360 data product across four key business domains: </p> <ul> <li>Customer Domain: CRM, loyalty program, support tickets, app usage</li> <li>Sales Domain: Transactions, line items, regional sales  </li> <li>Product Domain: Catalog, inventory, suppliers, relationships</li> <li>Logistics Domain: Shipments, warehouses, tracking events</li> </ul>"},{"location":"c360/data_models/#1-customer-domain","title":"1. Customer Domain","text":"<ul> <li>Data Sources: CRM system, loyalty program, support tickets, app usage logs</li> <li>Data samples: c360_mock_data/customer</li> </ul>"},{"location":"c360/data_models/#tables","title":"Tables:","text":""},{"location":"c360/data_models/#customerscsv","title":"customers.csv","text":"Column Type Description customer_id STRING Unique customer identifier first_name STRING Customer first name last_name STRING Customer last name email STRING Customer email address phone STRING Customer phone number date_of_birth DATE Customer date of birth gender STRING Customer gender (M/F/O) registration_date TIMESTAMP When customer registered customer_segment STRING Customer segment (Premium, Standard, Basic) preferred_channel STRING Preferred shopping channel (online, store, mobile) address_line1 STRING Primary address city STRING City state STRING State/Province zip_code STRING ZIP/Postal code country STRING Country"},{"location":"c360/data_models/#loyalty_programcsv","title":"loyalty_program.csv","text":"Column Type Description customer_id STRING Foreign key to customers loyalty_tier STRING Loyalty tier (Bronze, Silver, Gold, Platinum) points_balance INTEGER Current loyalty points points_earned_ytd INTEGER Points earned year-to-date points_redeemed_ytd INTEGER Points redeemed year-to-date tier_start_date DATE When current tier was achieved lifetime_value DECIMAL(10,2) Customer lifetime value"},{"location":"c360/data_models/#support_ticketscsv","title":"support_tickets.csv","text":"Column Type Description ticket_id STRING Unique ticket identifier customer_id STRING Foreign key to customers created_date TIMESTAMP When ticket was created resolved_date TIMESTAMP When ticket was resolved category STRING Issue category (billing, product, shipping, etc.) priority STRING Priority level (low, medium, high, urgent) status STRING Current status (open, in_progress, resolved, closed) channel STRING Contact channel (phone, email, chat, store) satisfaction_score INTEGER Customer satisfaction (1-5)"},{"location":"c360/data_models/#app_usagecsv","title":"app_usage.csv","text":"Column Type Description usage_id STRING Unique usage record identifier customer_id STRING Foreign key to customers session_date DATE Date of app usage session_start TIMESTAMP Session start time session_duration_minutes INTEGER Session duration in minutes pages_viewed INTEGER Number of pages viewed actions_taken INTEGER Number of actions taken device_type STRING Device type (ios, android, web) app_version STRING App version used"},{"location":"c360/data_models/#2-sales-domain","title":"2. Sales Domain","text":"<ul> <li>Data Sources: Point of Sale (POS) system, e-commerce transactions, regional sales ledgers</li> <li>Data samples: c360_mock_data/sales</li> </ul>"},{"location":"c360/data_models/#tables_1","title":"Tables:","text":""},{"location":"c360/data_models/#transactionscsv","title":"transactions.csv","text":"Column Type Description transaction_id STRING Unique transaction identifier customer_id STRING Foreign key to customers transaction_date TIMESTAMP When transaction occurred channel STRING Sales channel (store, online, mobile) store_id STRING Store identifier (null for online) payment_method STRING Payment method used subtotal DECIMAL(10,2) Subtotal before tax/discounts tax_amount DECIMAL(10,2) Tax amount discount_amount DECIMAL(10,2) Discount applied total_amount DECIMAL(10,2) Final transaction total currency STRING Currency code status STRING Transaction status (completed, cancelled, refunded)"},{"location":"c360/data_models/#transaction_itemscsv","title":"transaction_items.csv","text":"Column Type Description item_id STRING Unique line item identifier transaction_id STRING Foreign key to transactions product_id STRING Foreign key to products quantity INTEGER Quantity purchased unit_price DECIMAL(10,2) Price per unit line_total DECIMAL(10,2) Total for this line item discount_applied DECIMAL(10,2) Discount on this item"},{"location":"c360/data_models/#regional_salescsv","title":"regional_sales.csv","text":"Column Type Description region_id STRING Unique region identifier region_name STRING Region name country STRING Country sales_date DATE Sales date total_revenue DECIMAL(12,2) Total revenue for region/date total_transactions INTEGER Number of transactions average_order_value DECIMAL(10,2) Average order value"},{"location":"c360/data_models/#3-product-domain","title":"3. Product Domain","text":"<ul> <li>Data Sources: Product catalog, inventory system, supplier data</li> <li>Data samples: c360_mock_data/products</li> </ul>"},{"location":"c360/data_models/#tables_2","title":"Tables:","text":""},{"location":"c360/data_models/#productscsv","title":"products.csv","text":"Column Type Description product_id STRING Unique product identifier product_name STRING Product name category STRING Product category subcategory STRING Product subcategory brand STRING Product brand price DECIMAL(10,2) Current price cost DECIMAL(10,2) Product cost weight_kg DECIMAL(8,3) Product weight in kg dimensions STRING Product dimensions color STRING Product color size STRING Product size created_date DATE When product was created status STRING Product status (active, discontinued, seasonal)"},{"location":"c360/data_models/#inventorycsv","title":"inventory.csv","text":"Column Type Description inventory_id STRING Unique inventory record identifier product_id STRING Foreign key to products location_id STRING Warehouse or store identifier stock_quantity INTEGER Current stock level reserved_quantity INTEGER Reserved stock reorder_point INTEGER Reorder threshold max_stock_level INTEGER Maximum stock level last_updated TIMESTAMP When record was last updated"},{"location":"c360/data_models/#supplierscsv","title":"suppliers.csv","text":"Column Type Description supplier_id STRING Unique supplier identifier supplier_name STRING Supplier company name contact_person STRING Primary contact email STRING Contact email phone STRING Contact phone address STRING Supplier address country STRING Supplier country payment_terms STRING Payment terms quality_rating DECIMAL(3,2) Quality rating (1.00-5.00)"},{"location":"c360/data_models/#product_supplierscsv","title":"product_suppliers.csv","text":"Column Type Description product_id STRING Foreign key to products supplier_id STRING Foreign key to suppliers is_primary BOOLEAN Is primary supplier for this product cost_price DECIMAL(10,2) Cost from this supplier lead_time_days INTEGER Lead time in days"},{"location":"c360/data_models/#4-logistics-domain","title":"4. Logistics Domain","text":"<ul> <li>Data Sources: Warehouse management, shipping manifests, tracking data</li> <li>Data samples: c360_mock_data/logistic</li> </ul>"},{"location":"c360/data_models/#tables_3","title":"Tables:","text":""},{"location":"c360/data_models/#shipmentscsv","title":"shipments.csv","text":"Column Type Description shipment_id STRING Unique shipment identifier transaction_id STRING Foreign key to transactions tracking_number STRING Carrier tracking number carrier STRING Shipping carrier service_level STRING Service level (standard, expedited, overnight) origin_location STRING Origin warehouse/store destination_address STRING Destination address weight_kg DECIMAL(8,3) Shipment weight dimensions STRING Package dimensions ship_date DATE Date shipped estimated_delivery DATE Estimated delivery date actual_delivery DATE Actual delivery date delivery_status STRING Current delivery status shipping_cost DECIMAL(8,2) Shipping cost"},{"location":"c360/data_models/#warehouse_locationscsv","title":"warehouse_locations.csv","text":"Column Type Description location_id STRING Unique location identifier location_name STRING Location name location_type STRING Type (warehouse, distribution_center, store) address STRING Full address city STRING City state STRING State/Province country STRING Country capacity_cubic_meters INTEGER Storage capacity manager_name STRING Location manager"},{"location":"c360/data_models/#tracking_eventscsv","title":"tracking_events.csv","text":"Column Type Description event_id STRING Unique event identifier shipment_id STRING Foreign key to shipments event_timestamp TIMESTAMP When event occurred event_type STRING Event type (picked_up, in_transit, out_for_delivery, delivered, etc.) location STRING Event location description STRING Event description carrier_status STRING Carrier's status code"},{"location":"c360/data_models/#data-relationships","title":"Data Relationships","text":""},{"location":"c360/data_models/#key-relationships","title":"Key Relationships:","text":"<ul> <li><code>customers.customer_id</code> \u2192 Primary key for customer dimension</li> <li><code>transactions.customer_id</code> \u2192 Links sales to customers</li> <li><code>transaction_items.product_id</code> \u2192 Links sales to products</li> <li><code>shipments.transaction_id</code> \u2192 Links logistics to sales</li> <li><code>inventory.product_id</code> \u2192 Links inventory to products</li> <li><code>product_suppliers.product_id</code> \u2192 Links suppliers to products</li> </ul>"},{"location":"c360/data_models/#c360-integration-points","title":"C360 Integration Points:","text":"<ul> <li>Customer Profile: Combine customers, loyalty_program, support_tickets, app_usage</li> <li>Purchase History: Join transactions with transaction_items and products  </li> <li>Fulfillment Data: Link shipments and tracking_events to customer orders</li> <li>Product Preferences: Analyze transaction_items to understand product affinity</li> </ul>"},{"location":"c360/data_models/#mock-data-generation","title":"Mock Data Generation","text":"<ul> <li>Location: <code>c360_mock_data/</code> directory</li> <li>Volume: 15 CSV files with realistic mock data</li> <li>Quality: Referential integrity maintained across domains</li> <li>Structure:   <pre><code>c360_mock_data/\n\u251c\u2500\u2500 customer/     (4 files: customers, loyalty, support, app usage)\n\u251c\u2500\u2500 sales/        (3 files: transactions, items, regional data)\n\u251c\u2500\u2500 products/     (4 files: products, inventory, suppliers, relationships)  \n\u2514\u2500\u2500 logistics/    (3 files: shipments, locations, tracking)\n</code></pre></li> </ul>"},{"location":"c360/flink_project/","title":"Customer 360 Flink Implementation","text":"<p>The Flink implementation is using the same approach as the spark implementation. The sources of data are now becoming streams, and to support the Stream capability we use Apache Kafka.</p>"},{"location":"c360/spark_project/","title":"Customer 360 Spark Implementation","text":"<p>The Spark implementation for the Customer 360 analytics uses the Kimball methodology of Sources \u2192 Intermediates \u2192 Facts \u2192 Views.</p> <p>The demonstration supports a Customer 360 (C360) data product for a multi-channel retailer, following the data product architecture outlined in the design document. The project implements a complete data pipeline from mock data generation to final consumable analytics views.</p> <p>The spark-sql creates a Hive metastore to contain the persistent view definitions and the database schema metadata.</p> <p>As an analytical pipeline, the sources are processed at each spark session, on-demand, and there is no persistence of the computed results.</p>"},{"location":"c360/spark_project/#key-features","title":"Key Features","text":"<p>The implemented pipeline creates a comprehensive customer view for analytics, BI, and ML initiatives. The name of this data product is <code>customer_analytics_c360</code>.</p>"},{"location":"c360/spark_project/#data-pipeline-flow","title":"Data Pipeline Flow","text":"<pre><code>CSV Mock Data \u2192 Spark Sources \u2192 Intermediates \u2192 Facts \u2192 Data Product View\n</code></pre>"},{"location":"c360/spark_project/#customer-health-scoring","title":"Customer Health Scoring","text":""},{"location":"c360/spark_project/#rfm-analysis-health-scoring","title":"RFM Analysis &amp; Health Scoring","text":"<ul> <li>Recency Score (1-5): Based on last purchase date</li> <li>Frequency Score (1-5): Based on transaction count  </li> <li>Monetary Score (1-5): Based on total spending</li> <li>Customer Health Score: Composite metric for overall value</li> </ul>"},{"location":"c360/spark_project/#customer-status-classification","title":"Customer Status Classification","text":"<ul> <li>Active: Recent purchases (\u226430 days)</li> <li>At Risk: Moderate inactivity (31-90 days)</li> <li>Churned: Extended inactivity (&gt;90 days)</li> <li>Never Purchased: No transaction history</li> </ul>"},{"location":"c360/spark_project/#cross-domain-integration","title":"Cross-Domain Integration","text":"<ul> <li>Demographics: Age, generation, location, tenure</li> <li>Loyalty Program: Tier, points, lifetime value</li> <li>Purchase Behavior: Channels, frequency, preferences</li> <li>Support Interaction: Tickets, satisfaction, issues</li> <li>Digital Engagement: App usage, device types, engagement score</li> </ul>"},{"location":"c360/spark_project/#risk-opportunity-identification","title":"Risk &amp; Opportunity Identification","text":"<ul> <li>Churn Risk Flags: Based on activity and satisfaction</li> <li>Channel Expansion: Single-channel customers with growth potential</li> <li>Tier Upgrade: High-value customers in lower tiers</li> <li>App Adoption: Active customers not using digital channels</li> </ul>"},{"location":"c360/spark_project/#components","title":"Components","text":"<ul> <li>4 Source files: Raw data ingestion with enrichment</li> <li>1 Intermediate file: Customer-transaction integration layer</li> <li>1 Fact table: Complete customer profile with metrics</li> <li>1 Final view: Consumable data product</li> </ul>"},{"location":"c360/spark_project/#key-sql-files","title":"Key SQL Files","text":""},{"location":"c360/spark_project/#sources","title":"Sources","text":"<ul> <li><code>src_customers.sql</code> - Customer demographics with derived fields read from the raw_customers.</li> <li><code>src_loyalty_program.sql</code> - Loyalty data with tier analysis read from loyalty_program_raw</li> <li><code>src_transactions.sql</code> - Sales data with time-based enrichment read from transactions_raw</li> <li><code>src_products.sql</code> - Product catalog with category groupings read from products_raw</li> </ul>"},{"location":"c360/spark_project/#intermediates","title":"Intermediates","text":"<ul> <li><code>int_customer_transactions.sql</code> - Joined customer-transaction data</li> </ul>"},{"location":"c360/spark_project/#facts","title":"Facts","text":"<ul> <li><code>fct_customer_360_profile.sql</code> - Complete customer profile with metrics</li> </ul>"},{"location":"c360/spark_project/#views","title":"Views","text":"<ul> <li><code>customer_analytics_c360.sql</code> - Final data product for consumption</li> </ul>"},{"location":"c360/spark_project/#demonstration","title":"\ud83c\udf89 Demonstration","text":""},{"location":"c360/spark_project/#prerequisites","title":"Prerequisites","text":"<ul> <li>Apache Spark 3.x installed with <code>spark-sql</code> command available: <code>brew install apache-spark</code></li> </ul>"},{"location":"c360/spark_project/#step-by-step-execution","title":"Step by step execution","text":"<p>The following commands execute the pipeline step by step so we can understand the processing logic.</p> <pre><code># 0. start the shell in the c360_spark_processing\nspark-sql\n# 1. Load source views\nsource sources/src_customers.sql;\nselect * from src_customers;\nsource sources/src_loyalty_program.sql;\nselect * from src_loyalty_program;\nsource sources/src_transactions.sql;\nselect * from src_transactions;\nsource sources/src_products.sql;\nselect * from src_products;\n\n# 2. Verify tables\nshow tables;\ncustomers_raw\nloyalty_program_raw\nproducts_raw\nsrc_customers\nsrc_loyalty_program\nsrc_products\nsrc_transactions\ntransactions_raw\n\n# 3. Create intermediate views\nsource intermediates/int_customer_transactions.sql;\nselect * from int_customer_transactions;\n\n# 4. Build fact tables\nsource facts/fct_customer_360_profile.sql;\nselect * from fct_customer_360_profile;\n\n# 5. Create final data product view\nsource views/customer_analytics_c360.sql;\n\n# 6. Query the data product\nSELECT * FROM customer_analytics_c360 LIMIT 10;\n</code></pre> <p>The completion of this pipeline creates a <code>metastore_db</code> folder which is a Apache Spark's embedded Hive metastore database.</p> <p>The Hive Metastore stores metadata about databases, tables, views, and schemas. There is also a Derby Database used as the embedded database engine.</p>"},{"location":"c360/spark_project/#expected-results","title":"Expected Results","text":"<p>After successful execution, you'll see: - 15 customers processed from mock data - Pipeline Summary showing customer distribution - Top 5 customers by health score - All customers currently show \"Churned\" status (expected - mock data is from May/June 2024)</p> <p>Sample output:</p> <pre><code>Pipeline Summary: 15 total customers, 0 active, 15 at risk, 1.87 avg health score\nTop Customer: Lisa Anderson (CUST009) - Platinum tier, $1019.98 spent, 2.67 health score\n</code></pre>"},{"location":"c360/spark_project/#quick-execution","title":"Quick Execution","text":""},{"location":"c360/spark_project/#run-complete-pipeline-recommended","title":"Run Complete Pipeline (Recommended)","text":"<pre><code>cd c360_spark_processing\n./run_c360_pipeline.sh\n</code></pre>"},{"location":"c360/spark_project/#run-consolidated-sql-directly","title":"Run Consolidated SQL Directly","text":"<pre><code>cd c360_spark_processing  \nspark-sql -f c360_consolidated_pipeline.sql\n</code></pre>"},{"location":"c360/spark_project/#usage-examples","title":"Usage Examples","text":""},{"location":"c360/spark_project/#sample-customer-360-profile","title":"Sample Customer 360 Profile","text":"<pre><code>SELECT \n    customer_id,\n    first_name || ' ' || last_name as customer_name,\n    customer_segment,          -- Premium, Standard, Basic\n    loyalty_tier,             -- Platinum, Gold, Silver, Bronze\n    customer_status,          -- Active, At Risk, Churned\n    total_transactions,       -- Purchase frequency\n    total_spent,             -- Total lifetime spending\n    customer_health_score,   -- Composite RFM score (1-5)\n    churn_risk_flag,         -- Risk indicator\n    app_engagement_score     -- Digital engagement metric\nFROM customer_analytics_c360;\n</code></pre>"},{"location":"c360/spark_project/#marketing-use-cases","title":"Marketing Use Cases","text":"<pre><code>-- Identify churn risk customers for retention campaigns\nSELECT customer_id, first_name, last_name, customer_health_score\nFROM customer_analytics_c360 \nWHERE churn_risk_flag = 1 \n  AND lifetime_value &gt; 1000;\n\n-- Segment customers by generation for targeted messaging\nSELECT generation_segment, \n       COUNT(*) as customer_count,\n       AVG(lifetime_value) as avg_ltv\nFROM customer_analytics_c360 \nGROUP BY generation_segment;\n</code></pre>"},{"location":"c360/spark_project/#product-analysis","title":"Product Analysis","text":"<pre><code>-- Analyze channel expansion opportunities\nSELECT preferred_channel,\n       COUNT(*) as customers,\n       SUM(channel_expansion_opportunity) as expansion_opps\nFROM customer_analytics_c360\nGROUP BY preferred_channel;\n</code></pre>"},{"location":"c360/spark_project/#finance-analysis","title":"Finance Analysis","text":"<pre><code>-- Customer lifetime value by segment\nSELECT value_segment,\n       COUNT(*) as customers,\n       AVG(lifetime_value) as avg_ltv,\n       SUM(total_spent) as total_revenue\nFROM customer_analytics_c360\nGROUP BY value_segment;\n</code></pre>"},{"location":"c360/spark_project/#data-quality","title":"Data Quality","text":""},{"location":"c360/spark_project/#validation-rules","title":"Validation Rules","text":"<ul> <li>Customer ID must be present and unique</li> <li>Email addresses must be non-null and non-empty</li> <li>Transaction amounts must be positive</li> <li>Dates must be valid and reasonable</li> </ul>"},{"location":"c360/spark_project/#data-completeness","title":"Data Completeness","text":"<ul> <li>Customer data: 100% on key demographics</li> <li>Transaction data: 95%+ on purchase history</li> <li>Support data: Variable based on customer interaction</li> <li>App usage: Available for digital customers only</li> </ul>"},{"location":"c360/spark_project/#performance-considerations","title":"Performance Considerations","text":""},{"location":"c360/spark_project/#optimization-strategies","title":"Optimization Strategies","text":"<ul> <li>Partition by customer_id for efficient queries</li> <li>Index on frequently queried dimensions (customer_segment, loyalty_tier)</li> <li>Cache intermediate results for iterative analysis</li> <li>Use columnar storage (Parquet) for analytical workloads</li> </ul>"},{"location":"c360/spark_project/#scaling","title":"Scaling","text":"<ul> <li>Designed to handle millions of customers</li> <li>Horizontal scaling via Spark cluster</li> <li>Incremental processing for large datasets</li> <li>Real-time streaming integration capability</li> </ul>"},{"location":"c360/spark_project/#integration-points","title":"Integration Points","text":""},{"location":"c360/spark_project/#consuming-systems","title":"Consuming Systems","text":"<ul> <li>BI Tools: Tableau, Power BI, Looker</li> <li>ML Platforms: MLflow, PyTorsh, Notebook.</li> </ul>"},{"location":"c360/spark_project/#api-access","title":"API Access","text":"<pre><code># Python example for programmatic access\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName(\"C360Analysis\").getOrCreate()\nc360_df = spark.sql(\"SELECT * FROM customer_analytics_c360\")\nhigh_value_customers = c360_df.filter(\"customer_health_score &gt;= 4.0\")\n</code></pre>"}]}