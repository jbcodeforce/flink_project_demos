# Flink Project Demonstrations

This project includes a data as a product end to end demonstration from design to deployment to illustrate how to move from batch processing to real-time processing, shifting left to the pipeline architecture.

The source data as a product is built with batch processing using using Apache Spark, while the real-time processing is covered with Apache Flink, specially the Confluent Cloud Managed service for Flink.

Better to read the content using [the mkdoc published site](https://jbcodeforce.github.io/flink_project_demos/).

To run the different demonstrations:

* [Run batch processing and web app - see the readme](./c360_spark_processing/README.md)
* Run the Flink processing using Confluent Cloud for Flink and Kafka [see this readme.](./c360_flink_processing/README.md)
* Run the Flink processing using Confluent Platform for Flink and Kafka [see this readme]()

### References

* [Data as a product methodology](https://jbcodeforce.github.io/flink-studies/methodology/data_as_a_product/)
* [Managing your Shift Left Flink project - CLI](https://jbcodeforce.github.io/shift_left_utils) an opiniated solution to manage your Flink project at scale on Confluent Cloud.
* [From Spark to Flink migration with AI](https://jbcodeforce.github.io/shift_left_utils/coding/llm_based_translation/)
* [SQL Flink studies and best practices](https://jbcodeforce.github.io/flink-studies/coding/flink-sql/)

## üôè Support my work

Love it? Give it a ‚≠êÔ∏è by clicking below:

<a href="https://github.com/jbcodeforce/flink_project_demos/stargazers"><img src="https://img.shields.io/github/stars/jbcodeforce/flink_project_demos?style=social" style="margin-left:0;box-shadow:none;border-radius:0;height:24px"></a>